"""æœ´ç´ è´å¶æ–¯ç®—æ³•
ç›¸å…³ç†è®º ðŸ‘‰ https://github.com/xiligey/npml_theories/blob/master/classify/naive_bayes.md
"""
import numpy as np
from numpy import ndarray

from npml.model import Classifier
from npml.utils.exceptions import FitError


class NaiveBayes(Classifier):
    def __init__(self):
        super().__init__()
        self.dict_p_label = {}  # å­˜æ”¾æ¯ä¸ªç±»åˆ«çš„æ¦‚çŽ‡
        self.dict_p_feature_based_label = {}  # å­˜æ”¾æ¯ä¸ªç‰¹å¾åŸºäºŽæ¯ä¸ªç±»åˆ«çš„æ¦‚çŽ‡

    def fit(self, train_features: ndarray, train_labels: ndarray) -> None:
        """è®­ç»ƒ
        Args:
            train_features: (n_samples, n_features), è®­ç»ƒé›†çš„features
            train_labels: (n_samples,), è®­ç»ƒé›†çš„labels æ•´æ•°åž‹
        """
        n_samples, n_features = train_features.shape
        distinct_labels = np.unique(train_labels)  # è®¡ç®—æœ‰å¤šå°‘ä¸ªç±»åˆ«
        if distinct_labels.shape[0] == 1:
            raise FitError("Values of labels of train data must > 1")
        for distinct_label in distinct_labels:
            label_count = np.sum(train_labels == distinct_label)  # å½“å‰labelåœ¨è®­ç»ƒé›†ä¸­å‡ºçŽ°è¿‡çš„æ¬¡æ•°
            self.dict_p_label[distinct_label] = label_count / n_samples  # å°†å½“å‰labelå‘ç”Ÿçš„æ¦‚çŽ‡æ·»åŠ åˆ°dict_p_label
            if distinct_label not in self.dict_p_feature_based_label.keys():
                self.dict_p_feature_based_label[distinct_label] = {}
            for i in range(n_features):
                feature_i = train_features[i, :]  # ç¬¬iä¸ªæ ·æœ¬
                distinct_feature_values = np.unique(feature_i)
                if i not in self.dict_p_feature_based_label[distinct_label].keys():
                    self.dict_p_feature_based_label[distinct_label][i] = {}
                for feature_value in distinct_feature_values:
                    a = train_features[train_labels == distinct_label]
                    x = a[a[:, feature_i == feature_value]]
                    self.dict_p_feature_based_label[distinct_label][i][feature_value] = len(x) / label_count

    def predict(self, pred_features: ndarray) -> ndarray:
        """é¢„æµ‹
        Args:
            pred_features: (n_samples, n_features), å¾…é¢„æµ‹çš„æ•°æ®é›†
        Returns:
            (n_samples,), é¢„æµ‹ç»“æžœ
        """
        return np.array([self._predict_one_sample(i) for i in pred_features])

    def _predict_one_sample(self, sample: ndarray) -> int:
        """é¢„æµ‹ä¸€ä¸ªæ ·æœ¬ç‚¹çš„ç±»åˆ«
        Args:
            sample: (n_features,), å¸¦é¢„æµ‹çš„ä¸€ä¸ªæ ·æœ¬
        Returns:
            int, é¢„æµ‹çš„ç±»åˆ«
        """
        keys = self.dict_p_label.keys()
        labels = list(keys)
        probabilities = [self.dict_p_label[key] * np.prod([self.dict_p_feature_based_label[key][s] for s in sample]) for
                         key in keys]
        return labels[np.argmax(probabilities)]
